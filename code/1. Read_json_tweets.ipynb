{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction from imported JSON file from Twitter\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TwitterJSON manager class\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class definition \n",
    "class TwitterJsonMgr():\n",
    "    def __init__(self, filepath):\n",
    "        self._filepath = filepath\n",
    "        self.__StoreTweetDataToList()\n",
    "    \n",
    "    # define methods\n",
    "    def __StoreTweetDataToList(self):\n",
    "        self._tweetdata = []\n",
    "        for line in open(self._filepath):\n",
    "            try:\n",
    "                self._tweetdata.append(json.loads(line))\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    def __ExtractText(self):\n",
    "        texts = []\n",
    "        \n",
    "        for tweet in self._tweetdata:\n",
    "            try:\n",
    "                texts.append(tweet['text'])\n",
    "            except:\n",
    "                pass\n",
    "        return texts\n",
    "    \n",
    "    # define properties\n",
    "    def SetFilePath(self, filepath):\n",
    "        self._filepath = filepath\n",
    "    \n",
    "    def GetFilePath(self):\n",
    "        return self._filepath\n",
    "       \n",
    "    def GetTweetData(self):\n",
    "        return self._tweetdata\n",
    "    \n",
    "    def GetTweetCount(self):        \n",
    "        return len(self._tweetdata)\n",
    "    \n",
    "    def GetTexts(self):\n",
    "        return self.__ExtractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare variables\n",
    "# path = \"C://Dropbox/research-and-dissertation/final-dissertation/code/tweetdata/\"\n",
    "path = \"C://Dropbox/research-and-dissertation/final-dissertation/code/\"\n",
    "jsonfile_fakeclaim_twts = path+\"clean_fake_twts.json\" #\"fake_claim_tweets.json\"\n",
    "jsonfile_realclaim_twts = path+\"clean_real_twts.json\" #\"real_claim_tweets.json\"\n",
    "\n",
    "# instantiate JsonMgr object for fake claim tweets\n",
    "jsonmgr_fakeclaim_twts = TwitterJsonMgr(jsonfile_fakeclaim_twts)\n",
    "\n",
    "# instantiate JsonMgr object for real claim tweets\n",
    "jsonmgr_realclaim_twts = TwitterJsonMgr(jsonfile_realclaim_twts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the data stats\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Fake Claims: 6618\n",
      "Total Real Claims: 157362\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Fake Claims:\", +jsonmgr_fakeclaim_twts.GetTweetCount())\n",
    "print(\"Total Real Claims:\", +jsonmgr_realclaim_twts.GetTweetCount())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write functions to extract metadata out of tweets collected\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetHashTags(tweet):\n",
    "    if (tweet['entities']['hashtags'] != []):\n",
    "        hashCnt = len(tweet['entities']['hashtags'])\n",
    "        hashTags = \"\"\n",
    "        for i in range(hashCnt):            \n",
    "            if i>0:\n",
    "                hashTags = hashTags + \", \" +tweet['entities']['hashtags'][i]['text']\n",
    "            else:\n",
    "                hashTags = tweet['entities']['hashtags'][i]['text']\n",
    "        return hashTags\n",
    "    \n",
    "def GetUserMention(tweet):    \n",
    "    if (tweet['entities']['user_mentions'] != []):\n",
    "        usrMentionCnt = len(tweet['entities']['user_mentions'])\n",
    "        usrMentions = \"\"\n",
    "        for i in range(usrMentionCnt):            \n",
    "            if i>0:\n",
    "                usrMentions = usrMentions + \", \" +tweet['entities']['user_mentions'][i]['screen_name']\n",
    "            else:\n",
    "                usrMentions = tweet['entities']['user_mentions'][0]['screen_name']\n",
    "        return usrMentions\n",
    "    \n",
    "def GetURLs(tweet):\n",
    "    if (tweet['entities']['urls'] != []):\n",
    "        twtUrlsCnt = len(tweet['entities']['urls'])\n",
    "        twtUrls = \"\"\n",
    "        for i in range(twtUrlsCnt):            \n",
    "            if i>0:\n",
    "                twtUrls = twtUrls + \", \" +tweet['entities']['urls'][i]['expanded_url']\n",
    "            else:\n",
    "                twtUrls = tweet['entities']['urls'][0]['expanded_url']\n",
    "        return twtUrls    \n",
    "\n",
    "def GetURLsCnt(tweet):\n",
    "    if (tweet['entities']['urls'] != []):\n",
    "        twtUrlsCnt = len(tweet['entities']['urls'])\n",
    "        twtUrls = \"\"\n",
    "        for i in range(twtUrlsCnt):            \n",
    "            if i>0:\n",
    "                twtUrls = twtUrls + \", \" +tweet['entities']['urls'][i]['expanded_url']\n",
    "            else:\n",
    "                twtUrls = tweet['entities']['urls'][0]['expanded_url']\n",
    "        return twtUrls    \n",
    "    \n",
    "from datetime import datetime\n",
    "def GetUsrAccAgeInDays(tweet, refDate=datetime.now()):\n",
    "    usrCreatedDt = tweet['user']['created_at']\n",
    "    \n",
    "    # convert both datetime to same format before calculating the difference\n",
    "    dt_acc_creation = datetime.strftime(datetime.strptime(usrCreatedDt,'%a %b %d %H:%M:%S +0000 %Y'), '%Y-%m-%d %H:%M:%S')\n",
    "    dt_refDate = datetime.strftime(datetime.now() , '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # calculate the difference\n",
    "    dt_format = '%Y-%m-%d %H:%M:%S'\n",
    "    timedelta = (datetime.strptime(dt_refDate,dt_format) - datetime.strptime(dt_acc_creation,dt_format))\n",
    "    \n",
    "    # return days from the time delta object\n",
    "    return timedelta.days\n",
    "    \n",
    "def RetrieveTwtrMetaData(jsonMgrObj, label):\n",
    "    # fetch tweet data from the fake claim json manager object\n",
    "    tweets = jsonMgrObj.GetTweetData()\n",
    "\n",
    "    # populate data frame with the required metadata\n",
    "    tweet_df = pd.DataFrame()\n",
    "\n",
    "    for tweet in tweets:\n",
    "        # create temp variables to store the information from the tweet     \n",
    "        twtId = tweet['id']\n",
    "        twtTxt = tweet['text']\n",
    "        retwtCnt = tweet['retweet_count']\n",
    "        hashTagsCnt = len(tweet['entities']['hashtags'])\n",
    "        hashTags = GetHashTags(tweet)\n",
    "        usrMentionsCnt = len(tweet['entities']['user_mentions'])\n",
    "        usrMentions = GetUserMention(tweet)\n",
    "        twtUrlCnt = len(tweet['entities']['urls'])\n",
    "        \n",
    "        usrName = tweet['user']['screen_name']\n",
    "        usrAccAge = GetUsrAccAgeInDays(tweet)\n",
    "        usrTwtCnt = tweet['user']['statuses_count']\n",
    "        usrVrfd = tweet['user']['verified']\n",
    "        usrLoc = tweet['user']['location']        \n",
    "\n",
    "        # assign values to the temporary dataframe which will be passed to the master dataframe\n",
    "        temp_df = pd.DataFrame({\n",
    "                                    'twt-id':[twtId],\n",
    "                                    'twt-txt':[twtTxt],\n",
    "                                    'retwt-cnt':[retwtCnt],\n",
    "                                    'twt-hashtags-cnt': [hashTagsCnt],\n",
    "                                    'twt-hashtags':[hashTags],\n",
    "                                    'usr-mention-cnt':[usrMentionsCnt],\n",
    "                                    'usr-mention': [usrMentions],\n",
    "                                    'twt-url-cnt': [twtUrlCnt],            \n",
    "                                    'usr-name':[usrName],\n",
    "                                    'usr-acc-age':[usrAccAge],\n",
    "                                    'usr-twtcnt':[usrTwtCnt],\n",
    "                                    'usr-vrfd':[usrVrfd],\n",
    "                                    'usr-loc':[usrLoc],\n",
    "                                    'label': [label]            \n",
    "                               })\n",
    "\n",
    "        # update master data frame\n",
    "        tweet_df = tweet_df.append(temp_df, ignore_index = True)\n",
    "    \n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetrieveTwtrMetaData_01(jsonMgrObj, label):\n",
    "    # fetch tweet data from the fake claim json manager object\n",
    "    tweets = jsonMgrObj.GetTweetData()\n",
    "\n",
    "    # populate data frame with the required metadata\n",
    "    tweet_df = pd.DataFrame()\n",
    "    \n",
    "    i = 0\n",
    "    for tweet in tweets:\n",
    "        # create temp variables to store the information from the tweet     \n",
    "        twtId = tweet['id']\n",
    "        twtTxt = tweet['text']\n",
    "        retwtCnt = tweet['retweet_count']\n",
    "        hashTagsCnt = len(tweet['entities']['hashtags'])\n",
    "        hashTags = GetHashTags(tweet)\n",
    "        usrMentionsCnt = len(tweet['entities']['user_mentions'])\n",
    "        usrMentions = GetUserMention(tweet)\n",
    "        twtUrlCnt = len(tweet['entities']['urls'])\n",
    "        \n",
    "        usrName = tweet['user']['screen_name']\n",
    "        usrAccAge = GetUsrAccAgeInDays(tweet)\n",
    "        usrTwtCnt = tweet['user']['statuses_count']\n",
    "        usrVrfd = tweet['user']['verified']\n",
    "        usrLoc = tweet['user']['location']        \n",
    "\n",
    "        # assign values to the temporary dataframe which will be passed to the master dataframe\n",
    "        temp_df = pd.DataFrame({\n",
    "                                    'twt-id':[twtId],\n",
    "                                    'twt-txt':[twtTxt],\n",
    "                                    'retwt-cnt':[retwtCnt],\n",
    "                                    'twt-hashtags-cnt': [hashTagsCnt],\n",
    "                                    'twt-hashtags':[hashTags],\n",
    "                                    'usr-mention-cnt':[usrMentionsCnt],\n",
    "                                    'usr-mention': [usrMentions],\n",
    "                                    'twt-url-cnt': [twtUrlCnt],            \n",
    "                                    'usr-name':[usrName],\n",
    "                                    'usr-acc-age':[usrAccAge],\n",
    "                                    'usr-twtcnt':[usrTwtCnt],\n",
    "                                    'usr-vrfd':[usrVrfd],\n",
    "                                    'usr-loc':[usrLoc],\n",
    "                                    'label': [label]            \n",
    "                               })\n",
    "        i = i + 1\n",
    "        print(i)\n",
    "        # update master data frame\n",
    "        tweet_df = tweet_df.append(temp_df, ignore_index = True)\n",
    "    \n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve metadata for both fake and real claims and label them\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jsonmgr_fakeclaim_twts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5944a72f8916>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fake dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfake_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRetrieveTwtrMetaData_01\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjsonmgr_fakeclaim_twts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"fake\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Real dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mreal_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRetrieveTwtrMetaData_01\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjsonmgr_realclaim_twts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"real\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'jsonmgr_fakeclaim_twts' is not defined"
     ]
    }
   ],
   "source": [
    "# Fake dataframe\n",
    "fake_df = RetrieveTwtrMetaData_01(jsonmgr_fakeclaim_twts,\"fake\")\n",
    "\n",
    "# Real dataframe\n",
    "real_df = RetrieveTwtrMetaData_01(jsonmgr_realclaim_twts, \"real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  UNCOMMENT CODE FOR SAVING THE DATA TO OUTPUT FILE\n",
    "# output_path = \"C://GoogleDrive/dissertation/data/output/\"\n",
    "# real_df.to_csv(output_path+\"real_tweets.csv\", index=False)\n",
    "# fake_df.to_csv(output_path+\"fake_tweets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read pre-processed meta-data extracted files \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = pd.read_csv(\"C://GoogleDrive/dissertation/data/output/fake_tweets.csv\")\n",
    "real_df = pd.read_csv(\"C://GoogleDrive/dissertation/data/output/real_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6618, 14), (157362, 14))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_df.shape, real_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163980, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([real_df, fake_df])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"C://GoogleDrive/dissertation/data/output/\"\n",
    "\n",
    "# Save the consolidated tweets to a file for further processing\n",
    "df.to_csv(output_path+\"all_tweets.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
